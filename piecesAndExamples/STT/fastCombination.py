from vosk import Model, KaldiRecognizer
import pyaudio
import json
import numpy as np
import collections
import speech_recognition as sr
import time
import threading

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
SAMPLE_RATE = 16000
BUFFER_SIZE = 4096
AUDIO_DURATION = 2  # –í —Å–µ–∫—É–Ω–¥–∞—Ö
MAX_FRAMES = (SAMPLE_RATE // BUFFER_SIZE) * AUDIO_DURATION

def amplify_audio(audio_data, factor=5.0):
    audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32)
    audio_np *= factor
    audio_np = np.clip(audio_np, -32768, 32767).astype(np.int16)
    return audio_np.tobytes()

def is_speech(audio_data):
    audio_np = np.frombuffer(audio_data, dtype=np.int16)
    volume = np.abs(audio_np).mean()
    return volume > 300

def recognize_speech_buffer(audio_buffer):
    global googleRec

    audio_data = b''.join(audio_buffer)

    audio_data = sr.AudioData(audio_data, SAMPLE_RATE, 2)

    try:
        text = googleRec.recognize_google(audio_data, language="ru-RU")
        print("üé§ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:", text)
    except sr.UnknownValueError:
        print("‚ùå Google Speech –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª —Ä–µ—á—å")
    except sr.RequestError:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Google Speech API")

model = Model('./vosk-model-small-ru-0.22')
recognizer = KaldiRecognizer(model, 16000, '["–¥–∂–∞—Ä–≤–∏—Å", "–≤—å", "–≤", "–≤—å—é", "–≤—é", "–¥", "–∂", "–¥–∂", "–∂–∞", "–¥–∂–∞", "–∂–∞—Ä", "—Ä–∞–∑", "–≤–æ–π—Å", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", "–±—ã—Å—Ç—Ä–æ", "–≤–∏—Å", "–∂–∞—Ä–∞", "–¥–∞—Ä–≤–∏–Ω", "–∞—Ä—Ç", "–¥–∂–∞–∑", "–∂–∞—Ä—Ç", "–≤–∏—Ä—Ç", "—Ä–µ–∑—É—Å", "–±—ã—Å—Ç—Ä–æ–≤", "–∂–∞—Ä–∫–æ", "–≤–æ–π—Å–∫–∞"]')

audio = pyaudio.PyAudio()
stream = audio.open(format=pyaudio.paInt16, channels=1, rate=SAMPLE_RATE, input=True, frames_per_buffer=BUFFER_SIZE)
stream.start_stream()

audio_buffer = collections.deque(maxlen=MAX_FRAMES)

googleRec = sr.Recognizer()
is_recognized = False

def process_audio():
    global is_recognized
    while True:
        data = stream.read(BUFFER_SIZE, exception_on_overflow=False)
        data = amplify_audio(data)
        audio_buffer.append(data)

        if is_speech(data):
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                # print("‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–∞—è —Ñ—Ä–∞–∑–∞:", result.get("text", ""))
            else:
                partial_result = json.loads(recognizer.PartialResult())
                partial_text = partial_result.get("partial", "")
                
                if "–¥–∂–∞—Ä–≤–∏—Å" in partial_text.lower() and not is_recognized:
                    is_recognized = True 
                    print("‚úÖ (–ë–´–°–¢–†–û) –î–∂–∞—Ä–≤–∏—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω —á–∞—Å—Ç–∏—á–Ω–æ!")
                    threading.Thread(target=recognize_speech_buffer, args=(list(audio_buffer),), daemon=True).start()
                    is_recognized = False

audio_thread = threading.Thread(target=process_audio, daemon=True)
audio_thread.start()

while True:
    time.sleep(0.1)
